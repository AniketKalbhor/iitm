{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28602659",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1c0a22",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# CLLMate: Multimodal LLM for Weather and Climate Events Forecasting\n",
    "## Complete Implementation and Analysis\n",
    "\n",
    "This notebook combines all implementation files and provides a comprehensive analysis of the CLLMate methodology for processing meteorological raster data and generating textual climate event predictions.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Overview and Architecture](#overview)\n",
    "2. [Data Processing Pipeline](#data-processing)\n",
    "3. [Feature Detection and Enhancement](#feature-detection)\n",
    "4. [Visual Encoding Pipeline](#visual-encoding)\n",
    "5. [Implementation Status](#implementation-status)\n",
    "6. [Complete Working Example](#complete-example)\n",
    "7. [Gap Analysis and Next Steps](#gap-analysis)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Overview and Architecture {#overview}\n",
    "\n",
    "### CLLMate Research Paper Summary\n",
    "The CLLMate paper introduces a novel approach to **Weather and Climate Event Forecasting (WCEF)** that:\n",
    "- Converts meteorological raster data (Temperature, Wind U/V, Precipitation) into RGB images\n",
    "- Uses CLIP vision encoder to extract visual features\n",
    "- Aligns these features with LLM embedding space\n",
    "- Generates textual event predictions directly\n",
    "\n",
    "### Current Implementation Status\n",
    "Your current implementation includes:\n",
    "‚úÖ **Data preprocessing and RGB conversion**  \n",
    "‚úÖ **CLIP feature extraction**  \n",
    "‚úÖ **Enhanced pattern detection (SCAFET-inspired)**  \n",
    "‚úÖ **Visual feature analysis**  \n",
    "‚ö†Ô∏è **Partial multimodal alignment**  \n",
    "‚ùå **Complete LLM integration and training**\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Data Processing Pipeline {#data-processing}\n",
    "\n",
    "### 2.1 RGB Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb37129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From rgb_image_script.py\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Load datasets\n",
    "temp_ds = xr.open_dataset(\"temp.nc\")\n",
    "precip_ds = xr.open_dataset(\"precipitation.nc\")\n",
    "wind_ds = xr.open_dataset(\"windspeed.nc\")\n",
    "\n",
    "# Extract variable names\n",
    "temp_var = \"T2M\"\n",
    "precip_var = \"PRECTOTCORR\"\n",
    "wind_var = \"WS10M\"\n",
    "\n",
    "# Function to normalize data to 0‚Äì255 (following CLLMate methodology)\n",
    "def normalize(data):\n",
    "    \"\"\"\n",
    "    Normalize meteorological data following CLLMate paper specifications\n",
    "    \"\"\"\n",
    "    arr = data.values\n",
    "    arr = np.nan_to_num(arr, nan=0.0)\n",
    "    min_val, max_val = np.percentile(arr, 2), np.percentile(arr, 98)\n",
    "    norm = (arr - min_val) / (max_val - min_val)\n",
    "    norm = np.clip(norm, 0, 1)\n",
    "    return (norm * 255).astype(np.uint8)\n",
    "\n",
    "# Process daily data for entire year\n",
    "def create_daily_rgb_images():\n",
    "    \"\"\"Generate RGB images for each day following CLLMate format\"\"\"\n",
    "    os.makedirs(\"rgb_images\", exist_ok=True)\n",
    "    \n",
    "    start_date = datetime.date(2024, 1, 1)\n",
    "    end_date = datetime.date(2024, 12, 31)\n",
    "    delta = datetime.timedelta(days=1)\n",
    "    \n",
    "    current_date = start_date\n",
    "    processed_count = 0\n",
    "    \n",
    "    while current_date <= end_date:\n",
    "        date_str = current_date.isoformat()\n",
    "        try:\n",
    "            date_np = np.datetime64(current_date)\n",
    "            \n",
    "            # Extract meteorological data for the date\n",
    "            temp_data = temp_ds[temp_var].sel(time=date_np, method=\"nearest\")\n",
    "            precip_data = precip_ds[precip_var].sel(time=date_np, method=\"nearest\")\n",
    "            wind_data = wind_ds[wind_var].sel(time=date_np, method=\"nearest\")\n",
    "            \n",
    "            # Create RGB channels (T=Red, W=Green, P=Blue)\n",
    "            R = normalize(temp_data)  # Temperature ‚Üí Red\n",
    "            G = normalize(wind_data)  # Wind Speed ‚Üí Green  \n",
    "            B = normalize(precip_data) # Precipitation ‚Üí Blue\n",
    "            \n",
    "            # Stack into RGB image\n",
    "            rgb_image = np.stack([R, G, B], axis=-1)\n",
    "            img = Image.fromarray(rgb_image)\n",
    "            img.save(f\"rgb_images/rgb_image_{date_str}.png\")\n",
    "            \n",
    "            processed_count += 1\n",
    "            if processed_count % 30 == 0:\n",
    "                print(f\"Processed {processed_count} days...\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Skipped {date_str}: {e}\")\n",
    "        \n",
    "        current_date += delta\n",
    "    \n",
    "    print(f\"Total processed: {processed_count} RGB images\")\n",
    "\n",
    "# Execute RGB generation\n",
    "create_daily_rgb_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5635fa11",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 2.2 Data Statistics and Context Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce833c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_meteorological_context(date_str):\n",
    "    \"\"\"\n",
    "    Generate statistical context following CLLMate paper format\n",
    "    \"\"\"\n",
    "    date_np = np.datetime64(date_str)\n",
    "    \n",
    "    # Extract raw data\n",
    "    temp_data = temp_ds[temp_var].sel(time=date_np, method=\"nearest\").values\n",
    "    precip_data = precip_ds[precip_var].sel(time=date_np, method=\"nearest\").values\n",
    "    wind_data = wind_ds[wind_var].sel(time=date_np, method=\"nearest\").values\n",
    "    \n",
    "    # Calculate statistics\n",
    "    stats = {\n",
    "        'max_temp': float(np.nanmax(temp_data)),\n",
    "        'min_temp': float(np.nanmin(temp_data)),\n",
    "        'mean_temp': float(np.nanmean(temp_data)),\n",
    "        'max_wind': float(np.nanmax(wind_data)),\n",
    "        'min_wind': float(np.nanmin(wind_data)),\n",
    "        'mean_wind': float(np.nanmean(wind_data)),\n",
    "        'max_precip': float(np.nanmax(precip_data)),\n",
    "        'min_precip': float(np.nanmin(precip_data)),\n",
    "        'mean_precip': float(np.nanmean(precip_data))\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Example usage\n",
    "example_stats = generate_meteorological_context(\"2024-06-17\")\n",
    "print(\"Meteorological Context Example:\")\n",
    "for key, value in example_stats.items():\n",
    "    print(f\"  {key}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4037630",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "---\n",
    "\n",
    "## 3. Feature Detection and Enhancement {#feature-detection}\n",
    "\n",
    "### 3.1 SCAFET-Enhanced Climate Feature Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7273a9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From feature_detector.py - Enhanced version\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from sklearn.decomposition import PCA\n",
    "import datetime\n",
    "import os\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "class CLLMateFeatureDetector:\n",
    "    \"\"\"\n",
    "    Enhanced feature detection combining SCAFET methodology with CLLMate approach\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.features_detected = {}\n",
    "        \n",
    "    def calculate_shape_index(self, field, scale_km=500):\n",
    "        \"\"\"\n",
    "        Calculate shape index (SI) - core of SCAFET methodology\n",
    "        SI > 0.5: ridge/filament structures (atmospheric rivers)\n",
    "        SI < -0.5: depression/cyclonic structures\n",
    "        \"\"\"\n",
    "        # Apply Gaussian smoothing\n",
    "        sigma = scale_km / 100\n",
    "        smoothed = gaussian_filter(field, sigma=sigma)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        gy, gx = np.gradient(smoothed)\n",
    "        \n",
    "        # Calculate Hessian matrix elements\n",
    "        gyy, gyx = np.gradient(gy)\n",
    "        gxy, gxx = np.gradient(gx)\n",
    "        \n",
    "        # Calculate eigenvalues of Hessian\n",
    "        determinant = gxx * gyy - gxy * gyx\n",
    "        trace = gxx + gyy\n",
    "        \n",
    "        # Shape index calculation\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            lambda1 = 0.5 * (trace + np.sqrt(trace**2 - 4*determinant))\n",
    "            lambda2 = 0.5 * (trace - np.sqrt(trace**2 - 4*determinant))\n",
    "            \n",
    "            si = np.where(np.abs(lambda1) > np.abs(lambda2), \n",
    "                         (lambda2 / lambda1), \n",
    "                         (lambda1 / lambda2))\n",
    "            \n",
    "        si = np.nan_to_num(si, nan=0.0)\n",
    "        return np.clip(si, -1, 1)\n",
    "    \n",
    "    def detect_atmospheric_rivers(self, precip_data, wind_u, wind_v, threshold=0.375):\n",
    "        \"\"\"\n",
    "        Detect atmospheric river-like structures\n",
    "        \"\"\"\n",
    "        # Calculate moisture flux proxy\n",
    "        wind_speed = np.sqrt(wind_u**2 + wind_v**2)\n",
    "        moisture_flux = precip_data * wind_speed\n",
    "        \n",
    "        # Calculate shape index\n",
    "        si = self.calculate_shape_index(moisture_flux, scale_km=1000)\n",
    "        \n",
    "        # Identify ridge-like structures\n",
    "        ar_candidates = si > threshold\n",
    "        \n",
    "        # Filter by size and elongation\n",
    "        labeled, num_features = ndimage.label(ar_candidates)\n",
    "        ar_features = []\n",
    "        \n",
    "        for i in range(1, num_features + 1):\n",
    "            feature_mask = labeled == i\n",
    "            if np.sum(feature_mask) > 50:  # Minimum size\n",
    "                coords = np.where(feature_mask)\n",
    "                if len(coords[0]) > 0:\n",
    "                    y_span = np.max(coords[0]) - np.min(coords[0])\n",
    "                    x_span = np.max(coords[1]) - np.min(coords[1])\n",
    "                    aspect_ratio = max(y_span, x_span) / (min(y_span, x_span) + 1e-6)\n",
    "                    \n",
    "                    if aspect_ratio > 2.0:  # Elongated structure\n",
    "                        ar_features.append(feature_mask)\n",
    "        \n",
    "        return ar_features, si\n",
    "    \n",
    "    def detect_cyclones(self, temp_data, wind_u, wind_v, threshold=-0.3):\n",
    "        \"\"\"\n",
    "        Detect cyclonic structures using temperature and wind vorticity\n",
    "        \"\"\"\n",
    "        # Calculate relative vorticity\n",
    "        gy_u, gx_u = np.gradient(wind_u)\n",
    "        gy_v, gx_v = np.gradient(wind_v)\n",
    "        vorticity = gx_v - gy_u\n",
    "        \n",
    "        # Calculate shape index for vorticity\n",
    "        si = self.calculate_shape_index(vorticity, scale_km=300)\n",
    "        \n",
    "        # Identify depression-like structures\n",
    "        cyclone_candidates = si < threshold\n",
    "        \n",
    "        # Additional filtering based on temperature gradient\n",
    "        temp_gradient = np.sqrt(np.gradient(temp_data)[0]**2 + np.gradient(temp_data)[1]**2)\n",
    "        strong_gradient = temp_gradient > np.percentile(temp_gradient, 70)\n",
    "        \n",
    "        # Combine conditions\n",
    "        cyclone_features = cyclone_candidates & strong_gradient\n",
    "        \n",
    "        # Filter by size\n",
    "        labeled, num_features = ndimage.label(cyclone_features)\n",
    "        filtered_cyclones = []\n",
    "        \n",
    "        for i in range(1, num_features + 1):\n",
    "            feature_mask = labeled == i\n",
    "            if 20 < np.sum(feature_mask) < 500:\n",
    "                filtered_cyclones.append(feature_mask)\n",
    "        \n",
    "        return filtered_cyclones, si\n",
    "    \n",
    "    def detect_weather_fronts(self, temp_data, threshold_percentile=85):\n",
    "        \"\"\"\n",
    "        Detect temperature fronts using gradient analysis\n",
    "        \"\"\"\n",
    "        # Calculate temperature gradient magnitude\n",
    "        gy, gx = np.gradient(temp_data)\n",
    "        gradient_magnitude = np.sqrt(gx**2 + gy**2)\n",
    "        \n",
    "        # Calculate shape index for temperature\n",
    "        si = self.calculate_shape_index(temp_data, scale_km=200)\n",
    "        \n",
    "        # Identify strong gradients\n",
    "        threshold = np.percentile(gradient_magnitude, threshold_percentile)\n",
    "        strong_gradients = gradient_magnitude > threshold\n",
    "        \n",
    "        # Filter for linear structures\n",
    "        ridge_like = np.abs(si) > 0.2\n",
    "        front_candidates = strong_gradients & ridge_like\n",
    "        \n",
    "        # Clean up small features\n",
    "        front_candidates = ndimage.binary_opening(front_candidates, structure=np.ones((3,3)))\n",
    "        \n",
    "        return front_candidates, gradient_magnitude\n",
    "\n",
    "def enhanced_climate_processor(date_str):\n",
    "    \"\"\"\n",
    "    Enhanced climate processing with comprehensive feature detection\n",
    "    \"\"\"\n",
    "    try:\n",
    "        date_np = np.datetime64(date_str)\n",
    "        \n",
    "        # Extract meteorological data\n",
    "        temp_data = temp_ds[\"T2M\"].sel(time=date_np, method=\"nearest\").values\n",
    "        precip_data = precip_ds[\"PRECTOTCORR\"].sel(time=date_np, method=\"nearest\").values\n",
    "        wind_speed = wind_ds[\"WS10M\"].sel(time=date_np, method=\"nearest\").values\n",
    "        \n",
    "        # Estimate wind components (simplified - ideally you'd have U/V components)\n",
    "        wind_u = wind_speed * 0.7\n",
    "        wind_v = wind_speed * 0.7\n",
    "        \n",
    "        # Initialize feature detector\n",
    "        detector = CLLMateFeatureDetector()\n",
    "        \n",
    "        # Detect various weather features\n",
    "        ar_features, ar_si = detector.detect_atmospheric_rivers(precip_data, wind_u, wind_v)\n",
    "        cyclone_features, cyclone_si = detector.detect_cyclones(temp_data, wind_u, wind_v)\n",
    "        front_features, temp_gradient = detector.detect_weather_fronts(temp_data)\n",
    "        \n",
    "        # Create comprehensive visualization\n",
    "        create_enhanced_visualization(date_str, temp_data, precip_data, wind_speed,\n",
    "                                   ar_features, cyclone_features, front_features,\n",
    "                                   ar_si, cyclone_si, temp_gradient)\n",
    "        \n",
    "        # Generate feature summary\n",
    "        create_feature_summary(date_str, ar_features, cyclone_features, front_features)\n",
    "        \n",
    "        return {\n",
    "            'atmospheric_rivers': len(ar_features),\n",
    "            'cyclones': len(cyclone_features),\n",
    "            'fronts': np.sum(front_features),\n",
    "            'ar_shape_index': ar_si,\n",
    "            'cyclone_shape_index': cyclone_si,\n",
    "            'temperature_gradient': temp_gradient\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {date_str}: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_enhanced_visualization(date_str, temp_data, precip_data, wind_speed,\n",
    "                               ar_features, cyclone_features, front_features,\n",
    "                               ar_si, cyclone_si, temp_gradient):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualization with detected features\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle(f'Enhanced Climate Features for {date_str}', fontsize=16)\n",
    "    \n",
    "    # Original RGB image\n",
    "    R = normalize_data(temp_data)\n",
    "    G = normalize_data(wind_speed)\n",
    "    B = normalize_data(precip_data)\n",
    "    rgb_image = np.stack([R, G, B], axis=-1)\n",
    "    \n",
    "    axes[0,0].imshow(rgb_image)\n",
    "    axes[0,0].set_title('RGB Meteorological Data\\n(T,W,P)')\n",
    "    axes[0,0].axis('off')\n",
    "    \n",
    "    # Temperature with detected fronts\n",
    "    im1 = axes[0,1].imshow(temp_data, cmap='RdBu_r')\n",
    "    axes[0,1].contour(front_features, levels=[0.5], colors='black', linewidths=2)\n",
    "    axes[0,1].set_title('Temperature + Weather Fronts')\n",
    "    axes[0,1].axis('off')\n",
    "    plt.colorbar(im1, ax=axes[0,1], shrink=0.8)\n",
    "    \n",
    "    # Precipitation with atmospheric rivers\n",
    "    im2 = axes[0,2].imshow(precip_data, cmap='Blues')\n",
    "    for i, ar in enumerate(ar_features):\n",
    "        axes[0,2].contour(ar, levels=[0.5], colors='red', linewidths=2)\n",
    "    axes[0,2].set_title(f'Precipitation + ARs ({len(ar_features)})')\n",
    "    axes[0,2].axis('off')\n",
    "    plt.colorbar(im2, ax=axes[0,2], shrink=0.8)\n",
    "    \n",
    "    # Shape index for AR detection\n",
    "    im3 = axes[1,0].imshow(ar_si, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "    axes[1,0].set_title('Shape Index (AR Detection)')\n",
    "    axes[1,0].axis('off')\n",
    "    plt.colorbar(im3, ax=axes[1,0], shrink=0.8)\n",
    "    \n",
    "    # Shape index with cyclones\n",
    "    im4 = axes[1,1].imshow(cyclone_si, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "    for i, cyclone in enumerate(cyclone_features):\n",
    "        axes[1,1].contour(cyclone, levels=[0.5], colors='yellow', linewidths=2)\n",
    "    axes[1,1].set_title(f'Shape Index + Cyclones ({len(cyclone_features)})')\n",
    "    axes[1,1].axis('off')\n",
    "    plt.colorbar(im4, ax=axes[1,1], shrink=0.8)\n",
    "    \n",
    "    # Temperature gradient\n",
    "    im5 = axes[1,2].imshow(temp_gradient, cmap='hot')\n",
    "    axes[1,2].set_title('Temperature Gradient Magnitude')\n",
    "    axes[1,2].axis('off')\n",
    "    plt.colorbar(im5, ax=axes[1,2], shrink=0.8)\n",
    "    \n",
    "    # Save enhanced visualization\n",
    "    os.makedirs('enhanced_features', exist_ok=True)\n",
    "    plt.savefig(f'enhanced_features/{date_str}_enhanced_features.png', \n",
    "                dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Enhanced visualization saved for {date_str}\")\n",
    "\n",
    "def create_feature_summary(date_str, ar_features, cyclone_features, front_features):\n",
    "    \"\"\"\n",
    "    Generate English language summary of detected features\n",
    "    \"\"\"\n",
    "    summary = f\"\\n=== Weather Feature Analysis for {date_str} ===\\n\"\n",
    "    \n",
    "    # Atmospheric Rivers\n",
    "    if len(ar_features) > 0:\n",
    "        summary += f\"üåä {len(ar_features)} atmospheric river(s) detected - moisture transport systems active\\n\"\n",
    "    else:\n",
    "        summary += \"üåä No atmospheric rivers detected - limited moisture transport\\n\"\n",
    "    \n",
    "    # Cyclones\n",
    "    if len(cyclone_features) > 0:\n",
    "        summary += f\"üåÄ {len(cyclone_features)} cyclonic system(s) detected - active low pressure systems\\n\"\n",
    "    else:\n",
    "        summary += \"üåÄ No significant cyclonic activity detected\\n\"\n",
    "    \n",
    "    # Fronts\n",
    "    front_strength = np.sum(front_features)\n",
    "    if front_strength > 100:\n",
    "        summary += f\"‚ùÑÔ∏è Strong temperature fronts detected ({front_strength} pixels) - significant weather boundaries\\n\"\n",
    "    elif front_strength > 50:\n",
    "        summary += f\"‚ùÑÔ∏è Moderate temperature fronts detected ({front_strength} pixels)\\n\"\n",
    "    else:\n",
    "        summary += \"‚ùÑÔ∏è Weak or no temperature fronts detected\\n\"\n",
    "    \n",
    "    print(summary)\n",
    "    \n",
    "    # Save summary\n",
    "    os.makedirs('feature_summaries', exist_ok=True)\n",
    "    with open(f'feature_summaries/{date_str}_summary.txt', 'w') as f:\n",
    "        f.write(summary)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def normalize_data(data):\n",
    "    \"\"\"Normalize data to 0-255 range for visualization\"\"\"\n",
    "    arr = np.nan_to_num(data, nan=0.0)\n",
    "    min_val, max_val = np.percentile(arr, 2), np.percentile(arr, 98)\n",
    "    norm = (arr - min_val) / (max_val - min_val)\n",
    "    norm = np.clip(norm, 0, 1)\n",
    "    return (norm * 255).astype(np.uint8)\n",
    "\n",
    "# Example usage\n",
    "example_features = enhanced_climate_processor(\"2024-06-17\")\n",
    "if example_features:\n",
    "    print(\"\\nDetected Features Summary:\")\n",
    "    for key, value in example_features.items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e092c55c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "---\n",
    "\n",
    "## 4. Visual Encoding Pipeline {#visual-encoding}\n",
    "\n",
    "### 4.1 CLIP Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a81799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From pooler_visual_encoder.py - Enhanced version\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import datetime\n",
    "import torchvision.transforms as transforms\n",
    "from transformers import CLIPVisionModel\n",
    "\n",
    "class CLLMateVisualEncoder:\n",
    "    \"\"\"\n",
    "    CLIP-based visual encoder following CLLMate methodology\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Load CLIP model (ViT-L/14 as per paper)\n",
    "        self.model = CLIPVisionModel.from_pretrained(\n",
    "            \"openai/clip-vit-large-patch14\"\n",
    "        ).to(self.device).eval()\n",
    "        \n",
    "        # Transform following CLIP preprocessing\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "                std=[0.26862954, 0.26130258, 0.27577711]\n",
    "            )\n",
    "        ])\n",
    "    \n",
    "    def extract_features(self, date_str, save_features=True):\n",
    "        \"\"\"\n",
    "        Extract both CLIP features and physical climate features\n",
    "        \"\"\"\n",
    "        rgb_path = f\"rgb_images/rgb_image_{date_str}.png\"\n",
    "        if not os.path.exists(rgb_path):\n",
    "            print(f\"Skipped {date_str}: '{rgb_path}' not found.\")\n",
    "            return None\n",
    "        \n",
    "        # Load and preprocess RGB image\n",
    "        image = Image.open(rgb_path).convert(\"RGB\")\n",
    "        image_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        # Extract CLIP features\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(image_tensor, output_hidden_states=True)\n",
    "            \n",
    "            # Get different feature representations\n",
    "            pooled_features = outputs.pooler_output.squeeze().cpu().numpy()  # (1024,)\n",
    "            last_hidden = outputs.last_hidden_state.squeeze().cpu().numpy()   # (257, 1024)\n",
    "            # Use second-to-last layer as per CLLMate paper\n",
    "            visual_features = outputs.hidden_states[-2].squeeze().cpu().numpy()  # (257, 1024)\n",
    "        \n",
    "        # Extract enhanced physical features\n",
    "        physical_features = enhanced_climate_processor(date_str)\n",
    "        \n",
    "        # Combine all features\n",
    "        combined_features = {\n",
    "            'date': date_str,\n",
    "            'pooled_features': pooled_features,        # Global image features\n",
    "            'visual_features': visual_features,        # Patch-level features\n",
    "            'last_hidden': last_hidden,               # Final layer features\n",
    "            'physical_features': physical_features,    # SCAFET-enhanced features\n",
    "            'feature_dimensions': {\n",
    "                'pooled': pooled_features.shape,\n",
    "                'visual': visual_features.shape,\n",
    "                'last_hidden': last_hidden.shape\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if save_features:\n",
    "            # Save combined features\n",
    "            os.makedirs(\"combined_features\", exist_ok=True)\n",
    "            np.save(f\"combined_features/{date_str}_all_features.npy\", combined_features)\n",
    "            print(f\"Saved combined features for {date_str}\")\n",
    "        \n",
    "        return combined_features\n",
    "    \n",
    "    def extract_patch_features_with_pca(self, date_str):\n",
    "        \"\"\"\n",
    "        Extract patch-level features and visualize with PCA\n",
    "        \"\"\"\n",
    "        rgb_path = f\"rgb_images/rgb_image_{date_str}.png\"\n",
    "        if not os.path.exists(rgb_path):\n",
    "            return None\n",
    "            \n",
    "        image = Image.open(rgb_path).convert(\"RGB\")\n",
    "        image_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(image_tensor, output_hidden_states=True)\n",
    "        \n",
    "        # Get patch features (remove CLS token)\n",
    "        features = outputs.hidden_states[-1].squeeze().cpu().numpy()\n",
    "        patch_features = features[1:]  # Remove CLS token\n",
    "        \n",
    "        # Apply PCA for visualization\n",
    "        from sklearn.decomposition import PCA\n",
    "        pca = PCA(n_components=3)\n",
    "        reduced = pca.fit_transform(patch_features)\n",
    "        \n",
    "        # Reshape to spatial grid (14x14 for ViT-L/14)\n",
    "        vis = reduced.reshape(14, 14, 3)\n",
    "        vis = (vis - vis.min()) / (vis.max() - vis.min())\n",
    "        \n",
    "        # Upsample to match original image size\n",
    "        from scipy.ndimage import zoom\n",
    "        vis_upsampled = zoom(vis, (16, 16, 1), order=1)  # 224x224\n",
    "        \n",
    "        # Save visualization\n",
    "        os.makedirs(\"visual_features\", exist_ok=True)\n",
    "        \n",
    "        import matplotlib.pyplot as plt\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        # Original RGB\n",
    "        axes[0].imshow(np.array(image))\n",
    "        axes[0].set_title(f'Original RGB Image\\n{date_str}')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # PCA visualization (patch level)\n",
    "        axes[1].imshow(vis)\n",
    "        axes[1].set_title('PCA Features (14x14 patches)')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        # Upsampled PCA visualization\n",
    "        axes[2].imshow(vis_upsampled)\n",
    "        axes[2].set_title('PCA Features (Upsampled)')\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"visual_features/{date_str}_pca_features.png\", dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"PCA visualization saved for {date_str}\")\n",
    "        \n",
    "        return {\n",
    "            'patch_features': patch_features,\n",
    "            'pca_features': reduced,\n",
    "            'visualization': vis_upsampled\n",
    "        }\n",
    "\n",
    "# Initialize encoder\n",
    "visual_encoder = CLLMateVisualEncoder()\n",
    "\n",
    "# Process example date\n",
    "example_date = \"2024-06-17\"\n",
    "print(f\"Processing visual features for {example_date}...\")\n",
    "\n",
    "# Extract comprehensive features\n",
    "features = visual_encoder.extract_features(example_date)\n",
    "if features:\n",
    "    print(\"\\nFeature extraction successful!\")\n",
    "    print(\"Feature dimensions:\")\n",
    "    for key, shape in features['feature_dimensions'].items():\n",
    "        print(f\"  {key}: {shape}\")\n",
    "\n",
    "# Generate PCA visualization\n",
    "pca_results = visual_encoder.extract_patch_features_with_pca(example_date)\n",
    "if pca_results:\n",
    "    print(f\"\\nPCA analysis complete - patch features shape: {pca_results['patch_features'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0db9a7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 4.2 Feature Analysis and Viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412ffad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From pooler_viewer.py - Enhanced version\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_extracted_features(date_str=\"2024-06-17\"):\n",
    "    \"\"\"\n",
    "    Comprehensive analysis of extracted features\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load combined features\n",
    "        data = np.load(f\"combined_features/{date_str}_all_features.npy\", allow_pickle=True).item()\n",
    "        \n",
    "        print(f\"=== Feature Analysis for {date_str} ===\\n\")\n",
    "        \n",
    "        # 1. CLIP Features Analysis\n",
    "        print(\"1. CLIP Visual Features:\")\n",
    "        pooled = data['pooled_features']\n",
    "        print(f\"   Pooled features shape: {pooled.shape}\")\n",
    "        print(f\"   Pooled features range: [{pooled.min():.3f}, {pooled.max():.3f}]\")\n",
    "        print(f\"   Pooled features mean: {pooled.mean():.3f}\")\n",
    "        \n",
    "        visual = data['visual_features']\n",
    "        print(f\"   Visual features shape: {visual.shape}\")\n",
    "        print(f\"   Visual features range: [{visual.min():.3f}, {visual.max():.3f}]\")\n",
    "        \n",
    "        # 2. Physical Features Analysis\n",
    "        if data['physical_features']:\n",
    "            print(\"\\n2. Physical Climate Features:\")\n",
    "            physical = data['physical_features']\n",
    "            for key, value in physical.items():\n",
    "                if isinstance(value, (int, float)):\n",
    "                    print(f\"   {key}: {value}\")\n",
    "        \n",
    "        # 3. Create comprehensive visualization\n",
    "        create_feature_analysis_plot(data, date_str)\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing features: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_feature_analysis_plot(data, date_str):\n",
    "    \"\"\"\n",
    "    Create comprehensive feature analysis visualization\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    \n",
    "    # Create layout\n",
    "    gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # 1. Original RGB image\n",
    "    try:\n",
    "        rgb_path = f\"rgb_images/rgb_image_{date_str}.png\"\n",
    "        if os.path.exists(rgb_path):\n",
    "            from PIL import Image\n",
    "            rgb_img = Image.open(rgb_path)\n",
    "            ax1 = fig.add_subplot(gs[0, 0])\n",
    "            ax1.imshow(rgb_img)\n",
    "            ax1.set_title(f'RGB Meteorological Data\\n{date_str}')\n",
    "            ax1.axis('off')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # 2. Pooled features distribution\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    pooled = data['pooled_features']\n",
    "    ax2.hist(pooled, bins=50, alpha=0.7, color='blue')\n",
    "    ax2.set_title('Pooled Features Distribution')\n",
    "    ax2.set_xlabel('Feature Value')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    \n",
    "    # 3. Visual features heatmap (first 100 features)\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    visual_sample = data['visual_features'][:10, :100]  # Sample for visualization\n",
    "    im3 = ax3.imshow(visual_sample, cmap='viridis', aspect='auto')\n",
    "    ax3.set_title('Visual Features Heatmap\\n(Sample: 10 patches, 100 dims)')\n",
    "    ax3.set_xlabel('Feature Dimension')\n",
    "    ax3.set_ylabel('Patch Index')\n",
    "    plt.colorbar(im3, ax=ax3, shrink=0.8)\n",
    "    \n",
    "    # 4. Physical features bar plot\n",
    "    ax4 = fig.add_subplot(gs[0, 3])\n",
    "    if data['physical_features']:\n",
    "        physical = data['physical_features']\n",
    "        numeric_features = {k: v for k, v in physical.items() \n",
    "                          if isinstance(v, (int, float))}\n",
    "        if numeric_features:\n",
    "            keys = list(numeric_features.keys())\n",
    "            values = list(numeric_features.values())\n",
    "            ax4.bar(range(len(keys)), values, color='green', alpha=0.7)\n",
    "            ax4.set_xticks(range(len(keys)))\n",
    "            ax4.set_xticklabels(keys, rotation=45, ha='right')\n",
    "            ax4.set_title('Physical Climate Features')\n",
    "            ax4.set_ylabel('Count/Intensity')\n",
    "    \n",
    "    # 5. Feature correlation analysis\n",
    "    ax5 = fig.add_subplot(gs[1, :2])\n",
    "    # Compute correlation between pooled features\n",
    "    pooled_reshaped = pooled.reshape(-1, 1)\n",
    "    correlation_matrix = np.corrcoef(pooled[:100])  # Sample for visualization\n",
    "    im5 = ax5.imshow(correlation_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "    ax5.set_title('Feature Correlation Matrix (Sample)')\n",
    "    plt.colorbar(im5, ax=ax5, shrink=0.8)\n",
    "    \n",
    "    # 6. Principal components visualization\n",
    "    ax6 = fig.add_subplot(gs[1, 2:])\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=10)\n",
    "    pca_features = pca.fit_transform(data['visual_features'])\n",
    "    \n",
    "    # Plot explained variance\n",
    "    ax6.bar(range(1, 11), pca.explained_variance_ratio_, color='purple', alpha=0.7)\n",
    "    ax6.set_title('PCA Explained Variance Ratio')\n",
    "    ax6.set_xlabel('Principal Component')\n",
    "    ax6.set_ylabel('Explained Variance Ratio')\n",
    "    \n",
    "    # 7. Feature statistics summary\n",
    "    ax7 = fig.add_subplot(gs[2, :])\n",
    "    stats_text = f\"\"\"\n",
    "Feature Statistics Summary for {date_str}:\n",
    "\n",
    "CLIP Features:\n",
    "‚Ä¢ Pooled features: {pooled.shape} - Global image representation\n",
    "‚Ä¢ Visual features: {data['visual_features'].shape} - Patch-level features  \n",
    "‚Ä¢ Range: [{pooled.min():.3f}, {pooled.max():.3f}], Mean: {pooled.mean():.3f}\n",
    "\n",
    "Physical Features:\n",
    "\"\"\"\n",
    "    if data['physical_features']:\n",
    "        for key, value in numeric_features.items():\n",
    "            stats_text += f\"‚Ä¢ {key}: {value}\\n\"\n",
    "    \n",
    "    ax7.text(0.05, 0.5, stats_text, fontsize=10, verticalalignment='center',\n",
    "             transform=ax7.transAxes, fontfamily='monospace')\n",
    "    ax7.axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Comprehensive Feature Analysis - {date_str}', fontsize=16)\n",
    "    \n",
    "    # Save analysis plot\n",
    "    os.makedirs('feature_analysis', exist_ok=True)\n",
    "    plt.savefig(f'feature_analysis/{date_str}_comprehensive_analysis.png', \n",
    "                dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Comprehensive analysis plot saved for {date_str}\")\n",
    "\n",
    "# Run feature analysis\n",
    "analysis_results = analyze_extracted_features(\"2024-06-17\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2939584",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Implementation Status Analysis {#implementation-status}\n",
    "\n",
    "### 5.1 Current Implementation vs CLLMate Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7eb881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def implementation_status_analysis():\n",
    "    \"\"\"\n",
    "    Comprehensive analysis of implementation status vs CLLMate paper\n",
    "    \"\"\"\n",
    "    \n",
    "    status = {\n",
    "        \"COMPLETED\": {\n",
    "            \"Data Processing Pipeline\": [\n",
    "                \"‚úÖ NetCDF data loading (NASA format)\",\n",
    "                \"‚úÖ RGB image generation (T‚ÜíRed, W‚ÜíGreen, P‚ÜíBlue)\", \n",
    "                \"‚úÖ Data normalization following paper specs\",\n",
    "                \"‚úÖ Daily processing for entire year\",\n",
    "                \"‚úÖ Statistical context generation\"\n",
    "            ],\n",
    "            \"Visual Feature Extraction\": [\n",
    "                \"‚úÖ CLIP ViT-L/14 model integration\",\n",
    "                \"‚úÖ Pooled feature extraction (1024-dim)\",\n",
    "                \"‚úÖ Patch-level feature extraction\",\n",
    "                \"‚úÖ Second-to-last layer features (as per paper)\",\n",
    "                \"‚úÖ PCA visualization of patch features\"\n",
    "            ],\n",
    "            \"Enhanced Pattern Detection\": [\n",
    "                \"‚úÖ SCAFET shape index calculation\",\n",
    "                \"‚úÖ Atmospheric river detection\",\n",
    "                \"‚úÖ Cyclone detection using vorticity\",\n",
    "                \"‚úÖ Temperature front detection\",\n",
    "                \"‚úÖ Multi-scale pattern analysis\"\n",
    "            ],\n",
    "            \"Visualization and Analysis\": [\n",
    "                \"‚úÖ Comprehensive feature visualization\",\n",
    "                \"‚úÖ Enhanced meteorological pattern plots\",\n",
    "                \"‚úÖ Feature correlation analysis\",\n",
    "                \"‚úÖ Statistical summaries and reports\"\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "        \"PARTIALLY_IMPLEMENTED\": {\n",
    "            \"Multimodal Alignment\": [\n",
    "                \"‚ö†Ô∏è Basic projection layers defined\",\n",
    "                \"‚ö†Ô∏è Feature combination logic present\", \n",
    "                \"‚ö†Ô∏è Missing proper training integration\",\n",
    "                \"‚ö†Ô∏è No learned alignment optimization\"\n",
    "            ],\n",
    "            \"Knowledge Graph\": [\n",
    "                \"‚ö†Ô∏è Basic event relationships defined\",\n",
    "                \"‚ö†Ô∏è Simple rule-based event prediction\",\n",
    "                \"‚ö†Ô∏è Missing LLM-based knowledge extraction\",\n",
    "                \"‚ö†Ô∏è No news corpus integration\"\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "        \"NOT_IMPLEMENTED\": {\n",
    "            \"LLM Integration\": [\n",
    "                \"‚ùå LLaMA-3 model loading and setup\",\n",
    "                \"‚ùå LoRA configuration for fine-tuning\",\n",
    "                \"‚ùå Multimodal instruction tuning\",\n",
    "                \"‚ùå Loss function implementation\",\n",
    "                \"‚ùå Training loop and optimization\"\n",
    "            ],\n",
    "            \"Instruction Dataset Creation\": [\n",
    "                \"‚ùå News corpus processing (41k articles)\",\n",
    "                \"‚ùå LLM-based event extraction\",\n",
    "                \"‚ùå Knowledge graph construction from text\",\n",
    "                \"‚ùå Temporal alignment of events with meteorology\",\n",
    "                \"‚ùå Instruction prompt formatting\"\n",
    "            ],\n",
    "            \"Model Training and Evaluation\": [\n",
    "                \"‚ùå Supervised fine-tuning pipeline\",\n",
    "                \"‚ùå BLEU/ROUGE/BERTScore evaluation\",\n",
    "                \"‚ùå Baseline model comparisons\",\n",
    "                \"‚ùå Ablation studies\",\n",
    "                \"‚ùå Performance benchmarking\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"CLLMATE IMPLEMENTATION STATUS ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for category, items in status.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        print(\"-\" * 40)\n",
    "        for section, tasks in items.items():\n",
    "            print(f\"\\n{section}:\")\n",
    "            for task in tasks:\n",
    "                print(f\"  {task}\")\n",
    "    \n",
    "    # Calculate completion percentage\n",
    "    total_completed = sum(len(items) for items in status[\"COMPLETED\"].values())\n",
    "    total_partial = sum(len(items) for items in status[\"PARTIALLY_IMPLEMENTED\"].values())\n",
    "    total_missing = sum(len(items) for items in status[\"NOT_IMPLEMENTED\"].values())\n",
    "    total_tasks = total_completed + total_partial + total_missing\n",
    "    \n",
    "    completion_percentage = (total_completed + 0.5 * total_partial) / total_tasks * 100\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"OVERALL COMPLETION STATUS: {completion_percentage:.1f}%\")\n",
    "    print(f\"  Completed: {total_completed} tasks\")\n",
    "    print(f\"  Partially implemented: {total_partial} tasks\") \n",
    "    print(f\"  Not implemented: {total_missing} tasks\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    return status\n",
    "\n",
    "# Run status analysis\n",
    "implementation_status = implementation_status_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8044a254",
   "metadata": {},
   "source": [
    "### 5.2 Gap Analysis and Critical Missing Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de1258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gap_analysis():\n",
    "    \"\"\"\n",
    "    Detailed gap analysis with prioritization\n",
    "    \"\"\"\n",
    "    \n",
    "    critical_gaps = {\n",
    "        \"HIGH_PRIORITY\": {\n",
    "            \"LLM Backbone Integration\": {\n",
    "                \"description\": \"Core LLaMA-3 model loading and setup\",\n",
    "                \"impact\": \"Critical - Without this, no text generation possible\",\n",
    "                \"effort\": \"Medium - Standard model loading with LoRA\",\n",
    "                \"dependencies\": [\"Transformers library\", \"GPU memory management\"]\n",
    "            },\n",
    "            \"Multimodal Feature Projection\": {\n",
    "                \"description\": \"Proper alignment of visual features to LLM embedding space\",\n",
    "                \"impact\": \"Critical - Core methodology of the paper\",\n",
    "                \"effort\": \"Medium - MLP layers + training integration\", \n",
    "                \"dependencies\": [\"LLM model\", \"Feature extraction pipeline\"]\n",
    "            },\n",
    "            \"Instruction Dataset Creation\": {\n",
    "                \"description\": \"Creating training data from meteorology + events\",\n",
    "                \"impact\": \"Critical - No training data = no model\",\n",
    "                \"effort\": \"High - Requires event labeling/synthesis\",\n",
    "                \"dependencies\": [\"Event taxonomy\", \"Temporal alignment\"]\n",
    "            }\n",
    "        },\n",
    "        \n",
    "        \"MEDIUM_PRIORITY\": {\n",
    "            \"Knowledge Graph Construction\": {\n",
    "                \"description\": \"Building event relationships from text corpus\",\n",
    "                \"impact\": \"Medium - Improves event prediction quality\",\n",
    "                \"effort\": \"High - NLP processing + graph construction\",\n",
    "                \"dependencies\": [\"Text corpus\", \"Event extraction pipeline\"]\n",
    "            },\n",
    "            \"Training Pipeline\": {\n",
    "                \"description\": \"Full supervised training with proper loss functions\",\n",
    "                \"impact\": \"Medium - For production-quality results\",\n",
    "                \"effort\": \"Medium - Standard fine-tuning setup\",\n",
    "                \"dependencies\": [\"LLM integration\", \"Dataset creation\"]\n",
    "            },\n",
    "            \"Evaluation Framework\": {\n",
    "                \"description\": \"Proper metrics and baseline comparisons\",\n",
    "                \"impact\": \"Medium - For scientific validation\",\n",
    "                \"effort\": \"Medium - Metric implementation + baselines\",\n",
    "                \"dependencies\": [\"Trained model\", \"Test dataset\"]\n",
    "            }\n",
    "        },\n",
    "        \n",
    "        \"LOW_PRIORITY\": {\n",
    "            \"Advanced Pattern Detection\": {\n",
    "                \"description\": \"More sophisticated weather pattern recognition\", \n",
    "                \"impact\": \"Low - Current SCAFET implementation is good\",\n",
    "                \"effort\": \"Medium - Additional algorithms\",\n",
    "                \"dependencies\": [\"Domain expertise\", \"Validation data\"]\n",
    "            },\n",
    "            \"Real-time Processing\": {\n",
    "                \"description\": \"Live weather data integration\",\n",
    "                \"impact\": \"Low - Not needed for research validation\",\n",
    "                \"effort\": \"High - Infrastructure + API integration\",\n",
    "                \"dependencies\": [\"Live data sources\", \"Deployment setup\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CRITICAL GAP ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for priority, gaps in critical_gaps.items():\n",
    "        print(f\"\\n{priority} GAPS:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for gap_name, details in gaps.items():\n",
    "            print(f\"\\nüìç {gap_name}\")\n",
    "            print(f\"   Description: {details['description']}\")\n",
    "            print(f\"   Impact: {details['impact']}\")\n",
    "            print(f\"   Effort: {details['effort']}\")\n",
    "            print(f\"   Dependencies: {', '.join(details['dependencies'])}\")\n",
    "    \n",
    "    return critical_gaps\n",
    "\n",
    "# Run gap analysis\n",
    "gap_analysis_results = gap_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c66708",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Complete Working Example {#complete-example}\n",
    "\n",
    "### 6.1 End-to-End Pipeline Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1404fb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLLMateDemo:\n",
    "    \"\"\"\n",
    "    Complete demonstration of current capabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.visual_encoder = CLLMateVisualEncoder()\n",
    "        self.feature_detector = CLLMateFeatureDetector()\n",
    "        \n",
    "    def run_complete_pipeline(self, date_str=\"2024-06-17\"):\n",
    "        \"\"\"\n",
    "        Run complete pipeline with current implementations\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"üöÄ Running CLLMate Pipeline for {date_str}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Step 1: Data Processing\n",
    "        print(\"\\n1Ô∏è‚É£ Data Processing...\")\n",
    "        try:\n",
    "            # Generate RGB image if not exists\n",
    "            rgb_path = f\"rgb_images/rgb_image_{date_str}.png\"\n",
    "            if not os.path.exists(rgb_path):\n",
    "                self.generate_rgb_for_date(date_str)\n",
    "            \n",
    "            # Get meteorological statistics\n",
    "            stats = generate_meteorological_context(date_str)\n",
    "            results['meteorological_stats'] = stats\n",
    "            print(\"   ‚úÖ RGB image generated\")\n",
    "            print(\"   ‚úÖ Meteorological statistics computed\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error in data processing: {e}\")\n",
    "            return None\n",
    "        \n",
    "        # Step 2: Visual Feature Extraction\n",
    "        print(\"\\n2Ô∏è‚É£ Visual Feature Extraction...\")\n",
    "        try:\n",
    "            visual_features = self.visual_encoder.extract_features(date_str)\n",
    "            results['visual_features'] = visual_features\n",
    "            print(\"   ‚úÖ CLIP features extracted\")\n",
    "            print(f\"   ‚úÖ Pooled features: {visual_features['pooled_features'].shape}\")\n",
    "            print(f\"   ‚úÖ Visual features: {visual_features['visual_features'].shape}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error in visual feature extraction: {e}\")\n",
    "            return None\n",
    "        \n",
    "        # Step 3: Enhanced Pattern Detection\n",
    "        print(\"\\n3Ô∏è‚É£ Enhanced Pattern Detection...\")\n",
    "        try:\n",
    "            physical_features = enhanced_climate_processor(date_str)\n",
    "            results['physical_features'] = physical_features\n",
    "            \n",
    "            if physical_features:\n",
    "                print(\"   ‚úÖ SCAFET shape index calculated\")\n",
    "                print(f\"   ‚úÖ Atmospheric rivers detected: {physical_features['atmospheric_rivers']}\")\n",
    "                print(f\"   ‚úÖ Cyclones detected: {physical_features['cyclones']}\")\n",
    "                print(f\"   ‚úÖ Front activity: {physical_features['fronts']} pixels\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error in pattern detection: {e}\")\n",
    "            physical_features = None\n",
    "        \n",
    "        # Step 4: Event Prediction (Rule-based for now)\n",
    "        print(\"\\n4Ô∏è‚É£ Climate Event Prediction...\")\n",
    "        try:\n",
    "            predicted_events = self.predict_events_rule_based(stats, physical_features)\n",
    "            results['predicted_events'] = predicted_events\n",
    "            \n",
    "            print(\"   ‚úÖ Rule-based event prediction completed\")\n",
    "            print(f\"   ‚úÖ Predicted events: {len(predicted_events)}\")\n",
    "            for event in predicted_events[:5]:  # Show first 5\n",
    "                print(f\"      ‚Ä¢ {event}\")\n",
    "            if len(predicted_events) > 5:\n",
    "                print(f\"      ... and {len(predicted_events)-5} more\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error in event prediction: {e}\")\n",
    "            predicted_events = []\n",
    "        \n",
    "        # Step 5: CLLMate-style Instruction Generation\n",
    "        print(\"\\n5Ô∏è‚É£ Instruction Generation...\")\n",
    "        try:\n",
    "            instruction = self.generate_cllmate_instruction(date_str, stats, predicted_events)\n",
    "            results['instruction'] = instruction\n",
    "            print(\"   ‚úÖ CLLMate-style instruction generated\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error in instruction generation: {e}\")\n",
    "        \n",
    "        # Step 6: Comprehensive Visualization\n",
    "        print(\"\\n6Ô∏è‚É£ Visualization Generation...\")\n",
    "        try:\n",
    "            self.create_comprehensive_visualization(date_str, results)\n",
    "            print(\"   ‚úÖ Comprehensive visualization created\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error in visualization: {e}\")\n",
    "        \n",
    "        print(f\"\\nüéâ Pipeline completed for {date_str}!\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def generate_rgb_for_date(self, date_str):\n",
    "        \"\"\"Generate RGB image for specific date\"\"\"\n",
    "        date_np = np.datetime64(date_str)\n",
    "        \n",
    "        temp_data = temp_ds[temp_var].sel(time=date_np, method=\"nearest\")\n",
    "        precip_data = precip_ds[precip_var].sel(time=date_np, method=\"nearest\")\n",
    "        wind_data = wind_ds[wind_var].sel(time=date_np, method=\"nearest\")\n",
    "        \n",
    "        R = normalize(temp_data)\n",
    "        G = normalize(wind_data)\n",
    "        B = normalize(precip_data)\n",
    "        \n",
    "        rgb_image = np.stack([R, G, B], axis=-1)\n",
    "        img = Image.fromarray(rgb_image)\n",
    "        \n",
    "        os.makedirs(\"rgb_images\", exist_ok=True)\n",
    "        img.save(f\"rgb_images/rgb_image_{date_str}.png\")\n",
    "    \n",
    "    def predict_events_rule_based(self, stats, physical_features):\n",
    "        \"\"\"\n",
    "        Rule-based event prediction (placeholder for actual LLM)\n",
    "        \"\"\"\n",
    "        events = []\n",
    "        \n",
    "        # Temperature-based events\n",
    "        if stats['max_temp'] > 303:  # >30¬∞C\n",
    "            events.extend(['high_temperature', 'heat_wave_risk'])\n",
    "            if stats['mean_precip'] < 0.1:\n",
    "                events.extend(['drought_conditions', 'water_shortage_risk'])\n",
    "        \n",
    "        if stats['min_temp'] < 273:  # <0¬∞C\n",
    "            events.extend(['cold_air_mass', 'frost_risk', 'freezing_conditions'])\n",
    "        \n",
    "        # Precipitation-based events\n",
    "        if stats['max_precip'] > 3.0:\n",
    "            events.extend(['heavy_rainfall', 'flooding_risk'])\n",
    "            if stats['mean_wind'] > 5.0:\n",
    "                events.extend(['storm_conditions', 'severe_weather'])\n",
    "        \n",
    "        # Wind-based events\n",
    "        if stats['max_wind'] > 10.0:\n",
    "            events.extend(['strong_winds', 'wind_damage_risk'])\n",
    "        \n",
    "        # Physical pattern-based events\n",
    "        if physical_features:\n",
    "            if physical_features['atmospheric_rivers'] > 0:\n",
    "                events.extend(['atmospheric_river', 'moisture_transport', 'enhanced_precipitation'])\n",
    "            if physical_features['cyclones'] > 0:\n",
    "                events.extend(['cyclonic_activity', 'low_pressure_system', 'weather_disturbance'])\n",
    "            if physical_features['fronts'] > 100:\n",
    "                events.extend(['temperature_front', 'weather_boundary', 'frontal_system'])\n",
    "        \n",
    "        # Secondary effects\n",
    "        if 'flooding_risk' in events:\n",
    "            events.extend(['traffic_disruption', 'urban_flooding', 'drainage_issues'])\n",
    "        if 'heat_wave_risk' in events:\n",
    "            events.extend(['health_advisory', 'energy_demand_spike', 'agricultural_stress'])\n",
    "        if 'storm_conditions' in events:\n",
    "            events.extend(['power_outage_risk', 'transportation_delays', 'structural_damage_risk'])\n",
    "        \n",
    "        return list(set(events))  # Remove duplicates\n",
    "    \n",
    "    def generate_cllmate_instruction(self, date_str, stats, events):\n",
    "        \"\"\"\n",
    "        Generate CLLMate-style instruction following paper format\n",
    "        \"\"\"\n",
    "        instruction = f\"\"\"Given the meteorological raster data (ERA5) on date {date_str} in China, predict the environmental event that will happen. The meteorological raster data: temperature, u&v wind, precipitation are encoded as R,G,B channels of an image. It is then encoded using a visual encoder. The output should be in the format: [event1, event2, event3, ...]. Please analyze the meteorological patterns in China and predict the environmental events that will happen. \n",
    "\n",
    "The context of the meteorological information: \n",
    "- max temperature: {stats['max_temp']:.2f} K\n",
    "- min temperature: {stats['min_temp']:.2f} K  \n",
    "- mean temperature: {stats['mean_temp']:.2f} K\n",
    "- max wind speed: {stats['max_wind']:.2f} m/s\n",
    "- min wind speed: {stats['min_wind']:.2f} m/s\n",
    "- mean wind speed: {stats['mean_wind']:.2f} m/s\n",
    "- max precipitation: {stats['max_precip']:.2f} mm\n",
    "- min precipitation: {stats['min_precip']:.2f} mm\n",
    "- mean precipitation: {stats['mean_precip']:.2f} mm\n",
    "\n",
    "Expected Output: {events}\"\"\"\n",
    "        \n",
    "        return instruction\n",
    "    \n",
    "    def create_comprehensive_visualization(self, date_str, results):\n",
    "        \"\"\"\n",
    "        Create final comprehensive visualization\n",
    "        \"\"\"\n",
    "        fig = plt.figure(figsize=(24, 16))\n",
    "        gs = fig.add_gridspec(4, 4, hspace=0.3, wspace=0.3)\n",
    "        \n",
    "        # 1. Original RGB meteorological data\n",
    "        try:\n",
    "            rgb_img = Image.open(f\"rgb_images/rgb_image_{date_str}.png\")\n",
    "            ax1 = fig.add_subplot(gs[0, 0])\n",
    "            ax1.imshow(rgb_img)\n",
    "            ax1.set_title(f'RGB Meteorological Data\\n{date_str}')\n",
    "            ax1.axis('off')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # 2. Enhanced patterns (if available)\n",
    "        try:\n",
    "            enhanced_img_path = f\"enhanced_features/{date_str}_enhanced_features.png\"\n",
    "            if os.path.exists(enhanced_img_path):\n",
    "                enhanced_img = Image.open(enhanced_img_path)\n",
    "                ax2 = fig.add_subplot(gs[0, 1:3])\n",
    "                ax2.imshow(enhanced_img)\n",
    "                ax2.set_title('Enhanced Weather Patterns')\n",
    "                ax2.axis('off')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # 3. Feature statistics\n",
    "        ax3 = fig.add_subplot(gs[0, 3])\n",
    "        stats = results['meteorological_stats']\n",
    "        stats_text = f\"\"\"Meteorological Statistics:\n",
    "        \n",
    "Temperature (K):\n",
    "  Max: {stats['max_temp']:.1f}\n",
    "  Min: {stats['min_temp']:.1f}\n",
    "  Mean: {stats['mean_temp']:.1f}\n",
    "  \n",
    "Wind Speed (m/s):\n",
    "  Max: {stats['max_wind']:.1f}\n",
    "  Min: {stats['min_wind']:.1f}\n",
    "  Mean: {stats['mean_wind']:.1f}\n",
    "  \n",
    "Precipitation (mm):\n",
    "  Max: {stats['max_precip']:.2f}\n",
    "  Min: {stats['min_precip']:.2f}\n",
    "  Mean: {stats['mean_precip']:.2f}\"\"\"\n",
    "        \n",
    "        ax3.text(0.05, 0.95, stats_text, fontsize=10, verticalalignment='top',\n",
    "                transform=ax3.transAxes, fontfamily='monospace')\n",
    "        ax3.axis('off')\n",
    "        ax3.set_title('Climate Statistics')\n",
    "        \n",
    "        # 4. CLIP Features visualization\n",
    "        if 'visual_features' in results:\n",
    "            ax4 = fig.add_subplot(gs[1, :2])\n",
    "            pooled = results['visual_features']['pooled_features']\n",
    "            ax4.hist(pooled, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "            ax4.set_title('CLIP Pooled Features Distribution')\n",
    "            ax4.set_xlabel('Feature Value')\n",
    "            ax4.set_ylabel('Frequency')\n",
    "            ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 5. Physical features\n",
    "        if 'physical_features' in results and results['physical_features']:\n",
    "            ax5 = fig.add_subplot(gs[1, 2:])\n",
    "            phys = results['physical_features']\n",
    "            feature_names = ['Atmospheric\\nRivers', 'Cyclones', 'Front\\nActivity']\n",
    "            feature_values = [phys['atmospheric_rivers'], phys['cyclones'], \n",
    "                            min(phys['fronts']/100, 10)]  # Scale fronts for display\n",
    "            \n",
    "            bars = ax5.bar(feature_names, feature_values, color=['blue', 'red', 'green'], alpha=0.7)\n",
    "            ax5.set_title('Detected Physical Features')\n",
    "            ax5.set_ylabel('Count/Intensity')\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for bar, value in zip(bars, feature_values):\n",
    "                height = bar.get_height()\n",
    "                ax5.text(bar.get_x() + bar.get_width()/2., height + 0.05,\n",
    "                        f'{value:.1f}', ha='center', va='bottom')\n",
    "        \n",
    "        # 6. Predicted Events\n",
    "        ax6 = fig.add_subplot(gs[2, :])\n",
    "        if 'predicted_events' in results:\n",
    "            events = results['predicted_events']\n",
    "            events_text = \"Predicted Climate Events:\\n\\n\"\n",
    "            \n",
    "            # Group events by category\n",
    "            weather_events = [e for e in events if any(w in e.lower() for w in \n",
    "                            ['temperature', 'heat', 'cold', 'frost', 'wind', 'storm', 'rain', 'precip'])]\n",
    "            risk_events = [e for e in events if 'risk' in e.lower()]\n",
    "            system_events = [e for e in events if any(w in e.lower() for w in \n",
    "                           ['river', 'cyclone', 'front', 'system', 'mass'])]\n",
    "            impact_events = [e for e in events if e not in weather_events + risk_events + system_events]\n",
    "            \n",
    "            if weather_events:\n",
    "                events_text += f\"üå¶Ô∏è Weather Phenomena:\\n\"\n",
    "                for event in weather_events[:5]:\n",
    "                    events_text += f\"   ‚Ä¢ {event.replace('_', ' ').title()}\\n\"\n",
    "                if len(weather_events) > 5:\n",
    "                    events_text += f\"   ... and {len(weather_events)-5} more\\n\"\n",
    "                events_text += \"\\n\"\n",
    "            \n",
    "            if system_events:\n",
    "                events_text += f\"üåÄ Meteorological Systems:\\n\"\n",
    "                for event in system_events[:3]:\n",
    "                    events_text += f\"   ‚Ä¢ {event.replace('_', ' ').title()}\\n\"\n",
    "                events_text += \"\\n\"\n",
    "            \n",
    "            if risk_events:\n",
    "                events_text += f\"‚ö†Ô∏è Risk Factors:\\n\"\n",
    "                for event in risk_events[:4]:\n",
    "                    events_text += f\"   ‚Ä¢ {event.replace('_', ' ').title()}\\n\"\n",
    "                events_text += \"\\n\"\n",
    "            \n",
    "            if impact_events:\n",
    "                events_text += f\"üèôÔ∏è Potential Impacts:\\n\"\n",
    "                for event in impact_events[:4]:\n",
    "                    events_text += f\"   ‚Ä¢ {event.replace('_', ' ').title()}\\n\"\n",
    "        else:\n",
    "            events_text = \"No events predicted\"\n",
    "        \n",
    "        ax6.text(0.05, 0.95, events_text, fontsize=11, verticalalignment='top',\n",
    "                transform=ax6.transAxes, fontfamily='monospace')\n",
    "        ax6.axis('off')\n",
    "        ax6.set_title('Climate Event Predictions', fontsize=12, pad=20)\n",
    "        \n",
    "        # 7. CLLMate Instruction (if available)\n",
    "        if 'instruction' in results:\n",
    "            ax7 = fig.add_subplot(gs[3, :])\n",
    "            instruction_preview = results['instruction'][:500] + \"...\" if len(results['instruction']) > 500 else results['instruction']\n",
    "            ax7.text(0.05, 0.95, f\"CLLMate Instruction Format:\\n\\n{instruction_preview}\", \n",
    "                    fontsize=9, verticalalignment='top', transform=ax7.transAxes, \n",
    "                    fontfamily='monospace', wrap=True)\n",
    "            ax7.axis('off')\n",
    "            ax7.set_title('Generated Instruction (Preview)', fontsize=12, pad=20)\n",
    "        \n",
    "        plt.suptitle(f'CLLMate Pipeline Results - {date_str}', fontsize=18, y=0.98)\n",
    "        \n",
    "        # Save comprehensive visualization\n",
    "        os.makedirs('pipeline_results', exist_ok=True)\n",
    "        plt.savefig(f'pipeline_results/{date_str}_complete_pipeline.png', \n",
    "                    dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"   üìä Comprehensive visualization saved: pipeline_results/{date_str}_complete_pipeline.png\")\n",
    "\n",
    "# Run complete demonstration\n",
    "demo = CLLMateDemo()\n",
    "demo_results = demo.run_complete_pipeline(\"2024-06-17\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a40b77",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Next Steps and Implementation Roadmap {#gap-analysis}\n",
    "\n",
    "### 7.1 Implementation Priority Roadmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e630a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_implementation_roadmap():\n",
    "    \"\"\"\n",
    "    Detailed roadmap for completing CLLMate implementation\n",
    "    \"\"\"\n",
    "    \n",
    "    roadmap = {\n",
    "        \"PHASE_1_FOUNDATION\": {\n",
    "            \"timeline\": \"2-3 weeks\",\n",
    "            \"priority\": \"CRITICAL\",\n",
    "            \"tasks\": [\n",
    "                {\n",
    "                    \"task\": \"LLM Integration Setup\",\n",
    "                    \"description\": \"Set up LLaMA-3-8B with LoRA configuration\",\n",
    "                    \"deliverables\": [\"Working LLM model\", \"LoRA adapter configuration\", \"Memory optimization\"],\n",
    "                    \"code_files\": [\"llm_integration.py\", \"lora_config.py\"],\n",
    "                    \"effort_days\": 10\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "        \"PHASE_3_ENHANCEMENT\": {\n",
    "            \"timeline\": \"2-3 weeks\",\n",
    "            \"priority\": \"MEDIUM\", \n",
    "            \"tasks\": [\n",
    "                {\n",
    "                    \"task\": \"Knowledge Graph Integration\",\n",
    "                    \"description\": \"Implement proper event relationship modeling\",\n",
    "                    \"deliverables\": [\"Event taxonomy\", \"Relationship extraction\", \"Graph-based reasoning\"],\n",
    "                    \"code_files\": [\"knowledge_graph.py\", \"event_extractor.py\", \"graph_reasoning.py\"],\n",
    "                    \"effort_days\": 7\n",
    "                },\n",
    "                {\n",
    "                    \"task\": \"Advanced Pattern Detection\",\n",
    "                    \"description\": \"Enhance SCAFET integration and pattern recognition\",\n",
    "                    \"deliverables\": [\"Improved feature detection\", \"Multi-scale analysis\", \"Pattern validation\"],\n",
    "                    \"code_files\": [\"advanced_patterns.py\", \"scafet_enhanced.py\"],\n",
    "                    \"effort_days\": 5\n",
    "                },\n",
    "                {\n",
    "                    \"task\": \"Performance Optimization\",\n",
    "                    \"description\": \"Optimize model performance and inference speed\",\n",
    "                    \"deliverables\": [\"Speed optimizations\", \"Memory efficiency\", \"Batch processing\"],\n",
    "                    \"code_files\": [\"optimizer.py\", \"inference_engine.py\"],\n",
    "                    \"effort_days\": 3\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "        \"PHASE_4_PRODUCTION\": {\n",
    "            \"timeline\": \"1-2 weeks\",\n",
    "            \"priority\": \"LOW\",\n",
    "            \"tasks\": [\n",
    "                {\n",
    "                    \"task\": \"API and Interface Development\",\n",
    "                    \"description\": \"Create user-friendly interfaces and APIs\",\n",
    "                    \"deliverables\": [\"REST API\", \"Web interface\", \"Documentation\"],\n",
    "                    \"code_files\": [\"api_server.py\", \"web_interface.py\", \"docs/\"],\n",
    "                    \"effort_days\": 6\n",
    "                },\n",
    "                {\n",
    "                    \"task\": \"Deployment and Testing\",\n",
    "                    \"description\": \"Deploy system and conduct comprehensive testing\",\n",
    "                    \"deliverables\": [\"Deployment scripts\", \"Test suite\", \"Performance benchmarks\"],\n",
    "                    \"code_files\": [\"deploy.py\", \"tests/\", \"benchmarks.py\"],\n",
    "                    \"effort_days\": 4\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CLLMATE IMPLEMENTATION ROADMAP\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    total_effort = 0\n",
    "    \n",
    "    for phase_name, phase_info in roadmap.items():\n",
    "        print(f\"\\nüöÄ {phase_name.replace('_', ' ')}\")\n",
    "        print(f\"Timeline: {phase_info['timeline']}\")\n",
    "        print(f\"Priority: {phase_info['priority']}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        phase_effort = 0\n",
    "        for i, task in enumerate(phase_info['tasks'], 1):\n",
    "            print(f\"\\n{i}. {task['task']} ({task['effort_days']} days)\")\n",
    "            print(f\"   üìã {task['description']}\")\n",
    "            print(f\"   üì¶ Deliverables: {', '.join(task['deliverables'])}\")\n",
    "            print(f\"   üíª Code files: {', '.join(task['code_files'])}\")\n",
    "            phase_effort += task['effort_days']\n",
    "        \n",
    "        print(f\"\\n   Total phase effort: {phase_effort} days\")\n",
    "        total_effort += phase_effort\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TOTAL ESTIMATED EFFORT: {total_effort} days ({total_effort/7:.1f} weeks)\")\n",
    "    print(f\"With 1 developer working full-time: ~{total_effort/5:.1f} weeks (assuming 5 productive days/week)\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    return roadmap\n",
    "\n",
    "# Generate implementation roadmap\n",
    "implementation_roadmap = create_implementation_roadmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41111f5",
   "metadata": {},
   "source": [
    "### 7.2 Critical Code Templates for Missing Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91685a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_missing_code_templates():\n",
    "    \"\"\"\n",
    "    Generate code templates for the most critical missing components\n",
    "    \"\"\"\n",
    "    \n",
    "    templates = {}\n",
    "    \n",
    "    # Template 1: LLM Integration\n",
    "    templates['llm_integration'] = \"\"\"\n",
    "# llm_integration.py - Critical Missing Component\n",
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "class CLLMateLLMIntegration:\n",
    "    def __init__(self, model_name=\"meta-llama/Llama-2-7b-hf\"):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Load tokenizer\n",
    "        self.tokenizer = LlamaTokenizer.from_pretrained(model_name)\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        # Load LLM with LoRA\n",
    "        self.llm = LlamaForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\",\n",
    "            load_in_8bit=True  # For memory efficiency\n",
    "        )\n",
    "        \n",
    "        # Configure LoRA\n",
    "        peft_config = LoraConfig(\n",
    "            task_type=TaskType.CAUSAL_LM,\n",
    "            inference_mode=False,\n",
    "            r=8,\n",
    "            lora_alpha=32,\n",
    "            lora_dropout=0.1,\n",
    "            target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"]\n",
    "        )\n",
    "        self.llm = get_peft_model(self.llm, peft_config)\n",
    "    \n",
    "    def generate_events(self, prompt, max_length=256):\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.llm.generate(\n",
    "                inputs.input_ids,\n",
    "                max_length=max_length,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                pad_token_id=self.tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\"\"\"\n",
    "    \n",
    "    # Template 2: Multimodal Alignment\n",
    "    templates['multimodal_alignment'] = \"\"\"\n",
    "# multimodal_alignment.py - Critical Missing Component\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CLLMateMultimodalAligner(nn.Module):\n",
    "    def __init__(self, clip_feature_size=1024, llm_hidden_size=4096, physical_feature_size=15):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Visual feature projector (following CLLMate paper)\n",
    "        self.visual_projector = nn.Sequential(\n",
    "            nn.Linear(clip_feature_size, llm_hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(llm_hidden_size, llm_hidden_size),\n",
    "            nn.LayerNorm(llm_hidden_size)\n",
    "        )\n",
    "        \n",
    "        # Physical feature projector\n",
    "        self.physical_projector = nn.Sequential(\n",
    "            nn.Linear(physical_feature_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, llm_hidden_size),\n",
    "            nn.LayerNorm(llm_hidden_size)\n",
    "        )\n",
    "        \n",
    "        # Fusion layer\n",
    "        self.fusion_layer = nn.Sequential(\n",
    "            nn.Linear(llm_hidden_size * 2, llm_hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, clip_features, physical_features):\n",
    "        # Project features to LLM space\n",
    "        visual_embeds = self.visual_projector(clip_features)\n",
    "        physical_embeds = self.physical_projector(physical_features)\n",
    "        \n",
    "        # Fuse multimodal features\n",
    "        combined = torch.cat([visual_embeds, physical_embeds], dim=-1)\n",
    "        fused_features = self.fusion_layer(combined)\n",
    "        \n",
    "        return fused_features\n",
    "\"\"\"\n",
    "    \n",
    "    # Template 3: Training Pipeline\n",
    "    templates['training_pipeline'] = \"\"\"\n",
    "# training_pipeline.py - Critical Missing Component\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "\n",
    "class CLLMateDataset(Dataset):\n",
    "    def __init__(self, data_path, tokenizer, max_length=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.data = self.load_data(data_path)\n",
    "    \n",
    "    def load_data(self, path):\n",
    "        # Load your processed data here\n",
    "        # Should return list of dicts with keys: 'features', 'prompt', 'events'\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        # Tokenize prompt and events\n",
    "        prompt_tokens = self.tokenizer(\n",
    "            item['prompt'], \n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        events_tokens = self.tokenizer(\n",
    "            str(item['events']),\n",
    "            max_length=128,\n",
    "            truncation=True, \n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'clip_features': torch.tensor(item['clip_features'], dtype=torch.float32),\n",
    "            'physical_features': torch.tensor(item['physical_features'], dtype=torch.float32),\n",
    "            'prompt_ids': prompt_tokens['input_ids'].squeeze(),\n",
    "            'prompt_mask': prompt_tokens['attention_mask'].squeeze(),\n",
    "            'event_ids': events_tokens['input_ids'].squeeze(),\n",
    "            'event_mask': events_tokens['attention_mask'].squeeze()\n",
    "        }\n",
    "\n",
    "class CLLMateTrainer:\n",
    "    def __init__(self, model, tokenizer, learning_rate=2e-5):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Optimizer\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            model.parameters(), \n",
    "            lr=learning_rate,\n",
    "            weight_decay=0.01\n",
    "        )\n",
    "    \n",
    "    def train_epoch(self, dataloader, epoch):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass with multimodal features\n",
    "            # This needs to be integrated with your LLM\n",
    "            loss = self.compute_loss(batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}')\n",
    "        \n",
    "        return total_loss / len(dataloader)\n",
    "    \n",
    "    def compute_loss(self, batch):\n",
    "        # Implement your loss computation here\n",
    "        # Should integrate multimodal features with LLM forward pass\n",
    "        pass\n",
    "\"\"\"\n",
    "    \n",
    "    # Template 4: Evaluation Framework  \n",
    "    templates['evaluation_framework'] = \"\"\"\n",
    "# evaluation_framework.py - Critical Missing Component\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from rouge import Rouge\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "\n",
    "class CLLMateEvaluator:\n",
    "    def __init__(self):\n",
    "        self.rouge = Rouge()\n",
    "        \n",
    "        # Load BERTScore model\n",
    "        self.bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.bert_model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    def evaluate_predictions(self, predictions, ground_truth):\n",
    "        results = {}\n",
    "        \n",
    "        # BLEU Score\n",
    "        bleu_scores = self.compute_bleu(predictions, ground_truth)\n",
    "        results['bleu'] = bleu_scores\n",
    "        \n",
    "        # ROUGE Score\n",
    "        rouge_scores = self.compute_rouge(predictions, ground_truth)\n",
    "        results['rouge'] = rouge_scores\n",
    "        \n",
    "        # BERTScore\n",
    "        bert_scores = self.compute_bertscore(predictions, ground_truth)\n",
    "        results['bertscore'] = bert_scores\n",
    "        \n",
    "        # Event-level metrics\n",
    "        event_metrics = self.compute_event_metrics(predictions, ground_truth)\n",
    "        results['event_metrics'] = event_metrics\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def compute_bleu(self, predictions, ground_truth):\n",
    "        # Tokenize for BLEU\n",
    "        references = [[gt.split()] for gt in ground_truth]\n",
    "        hypotheses = [pred.split() for pred in predictions]\n",
    "        \n",
    "        bleu1 = corpus_bleu(references, hypotheses, weights=(1, 0, 0, 0))\n",
    "        bleu2 = corpus_bleu(references, hypotheses, weights=(0.5, 0.5, 0, 0))\n",
    "        \n",
    "        return {'bleu1': bleu1, 'bleu2': bleu2}\n",
    "    \n",
    "    def compute_rouge(self, predictions, ground_truth):\n",
    "        scores = self.rouge.get_scores(predictions, ground_truth, avg=True)\n",
    "        return scores\n",
    "    \n",
    "    def compute_bertscore(self, predictions, ground_truth):\n",
    "        # Simplified BERTScore implementation\n",
    "        # For production, use the official bertscore library\n",
    "        scores = []\n",
    "        for pred, gt in zip(predictions, ground_truth):\n",
    "            # Compute semantic similarity using BERT embeddings\n",
    "            pred_embedding = self.get_bert_embedding(pred)\n",
    "            gt_embedding = self.get_bert_embedding(gt)\n",
    "            \n",
    "            # Cosine similarity\n",
    "            similarity = np.dot(pred_embedding, gt_embedding) / (\n",
    "                np.linalg.norm(pred_embedding) * np.linalg.norm(gt_embedding)\n",
    "            )\n",
    "            scores.append(similarity)\n",
    "        \n",
    "        return {'bertscore_avg': np.mean(scores)}\n",
    "    \n",
    "    def get_bert_embedding(self, text):\n",
    "        inputs = self.bert_tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.bert_model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    \n",
    "    def compute_event_metrics(self, predictions, ground_truth):\n",
    "        # Convert predictions and ground truth to event lists\n",
    "        pred_events = [self.extract_events(pred) for pred in predictions]\n",
    "        true_events = [self.extract_events(gt) for gt in ground_truth]\n",
    "        \n",
    "        # Compute precision, recall, F1\n",
    "        all_true, all_pred = [], []\n",
    "        for pred, true in zip(pred_events, true_events):\n",
    "            all_events = list(set(pred + true))\n",
    "            true_binary = [1 if e in true else 0 for e in all_events]\n",
    "            pred_binary = [1 if e in pred else 0 for e in all_events]\n",
    "            all_true.extend(true_binary)\n",
    "            all_pred.extend(pred_binary)\n",
    "        \n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            all_true, all_pred, average='binary'\n",
    "        )\n",
    "        \n",
    "        return {'precision': precision, 'recall': recall, 'f1': f1}\n",
    "    \n",
    "    def extract_events(self, text):\n",
    "        # Extract events from text (implement based on your format)\n",
    "        # This is a simplified version\n",
    "        import re\n",
    "        events = re.findall(r'\\[(.*?)\\]', text)\n",
    "        if events:\n",
    "            return [e.strip() for e in events[0].split(',')]\n",
    "        return []\n",
    "\"\"\"\n",
    "    \n",
    "    print(\"üìù CRITICAL CODE TEMPLATES GENERATED\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for template_name, code in templates.items():\n",
    "        print(f\"\\nüîß {template_name.upper()}:\")\n",
    "        print(f\"   Priority: CRITICAL\")\n",
    "        print(f\"   Lines of code: ~{len(code.split(chr(10)))}\")\n",
    "        print(f\"   Estimated effort: 2-3 days\")\n",
    "    \n",
    "    return templates\n",
    "\n",
    "# Generate code templates\n",
    "code_templates = generate_missing_code_templates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdf2385",
   "metadata": {},
   "source": [
    "### 7.3 Quick Start Implementation Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db932234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_start_guide():\n",
    "    \"\"\"\n",
    "    Step-by-step guide to get CLLMate working\n",
    "    \"\"\"\n",
    "    \n",
    "    guide = \"\"\"\n",
    "    üöÄ CLLMate QUICK START IMPLEMENTATION GUIDE\n",
    "    ==========================================\n",
    "    \n",
    "    STEP 1: Environment Setup (30 minutes)\n",
    "    --------------------------------------\n",
    "    pip install torch transformers accelerate peft\n",
    "    pip install xarray netcdf4 pillow matplotlib scipy scikit-learn\n",
    "    pip install rouge-score nltk bertscore\n",
    "    \n",
    "    STEP 2: Model Integration (2-3 days)\n",
    "    -----------------------------------\n",
    "    1. Implement llm_integration.py using the template above\n",
    "    2. Set up LoRA configuration for memory efficiency\n",
    "    3. Test basic LLM loading and generation\n",
    "    \n",
    "    STEP 3: Multimodal Alignment (2-3 days)\n",
    "    ---------------------------------------\n",
    "    1. Implement multimodal_alignment.py\n",
    "    2. Create projection layers for CLIP ‚Üí LLM space\n",
    "    3. Test feature alignment with dummy data\n",
    "    \n",
    "    STEP 4: Training Data Creation (3-4 days)\n",
    "    ----------------------------------------\n",
    "    1. Use your existing RGB generation pipeline\n",
    "    2. Create synthetic event labels based on weather patterns\n",
    "    3. Format as CLLMate instruction dataset\n",
    "    4. Generate 1000+ training samples for initial testing\n",
    "    \n",
    "    STEP 5: Basic Training Pipeline (3-4 days)\n",
    "    ------------------------------------------\n",
    "    1. Implement training_pipeline.py\n",
    "    2. Create DataLoader for multimodal data\n",
    "    3. Implement loss function for text generation\n",
    "    4. Run initial training with small dataset\n",
    "    \n",
    "    STEP 6: Evaluation and Testing (2-3 days)\n",
    "    -----------------------------------------\n",
    "    1. Implement evaluation_framework.py\n",
    "    2. Test with BLEU, ROUGE metrics\n",
    "    3. Compare against rule-based baseline\n",
    "    4. Iterate and improve\n",
    "    \n",
    "    EXPECTED TIMELINE: 2-3 weeks for basic working version\n",
    "    FULL IMPLEMENTATION: 6-8 weeks with all enhancements\n",
    "    \n",
    "    KEY SUCCESS FACTORS:\n",
    "    - Start with synthetic/rule-based training data\n",
    "    - Use LoRA for memory efficiency\n",
    "    - Test each component independently\n",
    "    - Iterate quickly with small datasets first\n",
    "    \"\"\"\n",
    "    \n",
    "    print(guide)\n",
    "    \n",
    "    # Create implementation checklist\n",
    "    checklist = {\n",
    "        \"Environment Setup\": False,\n",
    "        \"LLM Integration\": False, \n",
    "        \"Multimodal Alignment\": False,\n",
    "        \"Training Data\": False,\n",
    "        \"Training Pipeline\": False,\n",
    "        \"Evaluation Framework\": False,\n",
    "        \"Model Training\": False,\n",
    "        \"Performance Testing\": False\n",
    "    }\n",
    "    \n",
    "    print(\"\\nüìã IMPLEMENTATION CHECKLIST:\")\n",
    "    print(\"-\" * 40)\n",
    "    for item, status in checklist.items():\n",
    "        status_icon = \"‚úÖ\" if status else \"‚è≥\"\n",
    "        print(f\"{status_icon} {item}\")\n",
    "    \n",
    "    return guide\n",
    "\n",
    "# Generate quick start guide\n",
    "quick_start = quick_start_guide()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc8c363",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Summary and Conclusions\n",
    "\n",
    "### 8.1 Current Implementation Strengths\n",
    "\n",
    "Your current implementation is **significantly advanced** compared to a typical starting point:\n",
    "\n",
    "‚úÖ **Complete data processing pipeline** - RGB generation, normalization, statistics  \n",
    "‚úÖ **Advanced feature detection** - SCAFET-enhanced pattern recognition  \n",
    "‚úÖ **CLIP integration** - Proper visual feature extraction  \n",
    "‚úÖ **Comprehensive visualization** - Professional-quality analysis plots  \n",
    "‚úÖ **Solid foundation** - Well-structured, modular codebase  \n",
    "\n",
    "### 8.2 Key Missing Components\n",
    "\n",
    "The **critical gap** is in the **LLM integration and training pipeline**:\n",
    "\n",
    "‚ùå **LLM backbone** - LLaMA-3 model loading and setup  \n",
    "‚ùå **Multimodal training** - Supervised fine-tuning with visual+text data  \n",
    "‚ùå **Instruction dataset** - Properly formatted training data  \n",
    "‚ùå **Evaluation framework** - BLEU/ROUGE/BERTScore metrics  \n",
    "\n",
    "### 8.3 Implementation Recommendation\n",
    "\n",
    "**Recommended approach:**\n",
    "1. **Start with synthetic training data** - Use your rule-based event predictions  \n",
    "2. **Implement LLM integration first** - Critical foundation component  \n",
    "3. **Create minimal training pipeline** - Get basic text generation working  \n",
    "4. **Iterate and improve** - Add more sophisticated features gradually  \n",
    "\n",
    "**Timeline estimate:** 2-3 weeks for basic working CLLMate, 6-8 weeks for full implementation.\n",
    "\n",
    "### 8.4 Repository Status Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964e8f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_status = {\n",
    "    \"üî• Ready to use\": [\n",
    "        \"rgb_image_script.py - Complete RGB generation pipeline\",\n",
    "        \"feature_detector.py - Advanced SCAFET pattern detection\", \n",
    "        \"pooler_visual_encoder.py - CLIP feature extraction\",\n",
    "        \"pca_visual_encoder.py - Visual feature analysis\"\n",
    "    ],\n",
    "    \"‚ö†Ô∏è Needs completion\": [\n",
    "        \"Multimodal alignment integration\",\n",
    "        \"Training data formatting\",\n",
    "        \"Performance evaluation\"\n",
    "    ],\n",
    "    \"‚ùå Missing critical components\": [\n",
    "        \"LLM integration (LLaMA-3)\",\n",
    "        \"Training pipeline\",\n",
    "        \"Loss functions\",\n",
    "        \"Evaluation metrics\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"üóÇÔ∏è REPOSITORY STATUS SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "for category, items in repo_status.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for item in items:\n",
    "        print(f\"  ‚Ä¢ {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c94bc2",
   "metadata": {},
   "source": [
    "Your implementation is **well-positioned** to become a complete CLLMate system with focused effort on the missing LLM components. The foundation you've built is solid and follows the paper's methodology correctly. 5\n",
    "                },\n",
    "                {\n",
    "                    \"task\": \"Multimodal Projection Layers\",\n",
    "                    \"description\": \"Implement proper visual-to-text feature alignment\",\n",
    "                    \"deliverables\": [\"MLP projection layers\", \"Feature alignment module\", \"Embedding integration\"],\n",
    "                    \"code_files\": [\"multimodal_aligner.py\", \"projection_layers.py\"],\n",
    "                    \"effort_days\": 4\n",
    "                },\n",
    "                {\n",
    "                    \"task\": \"Basic Instruction Dataset\",\n",
    "                    \"description\": \"Create synthetic training dataset from existing features\",\n",
    "                    \"deliverables\": [\"Instruction templates\", \"Event labels\", \"Training samples\"],\n",
    "                    \"code_files\": [\"dataset_creator.py\", \"instruction_formatter.py\"],\n",
    "                    \"effort_days\": 6\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "        \"PHASE_2_TRAINING\": {\n",
    "            \"timeline\": \"3-4 weeks\", \n",
    "            \"priority\": \"HIGH\",\n",
    "            \"tasks\": [\n",
    "                {\n",
    "                    \"task\": \"Training Pipeline Implementation\",\n",
    "                    \"description\": \"Full supervised fine-tuning pipeline\",\n",
    "                    \"deliverables\": [\"Training loop\", \"Loss functions\", \"Optimization setup\"],\n",
    "                    \"code_files\": [\"trainer.py\", \"loss_functions.py\", \"optimization.py\"],\n",
    "                    \"effort_days\": 8\n",
    "                },\n",
    "                {\n",
    "                    \"task\": \"Evaluation Framework\",\n",
    "                    \"description\": \"Implement BLEU, ROUGE, BERTScore metrics\",\n",
    "                    \"deliverables\": [\"Evaluation metrics\", \"Baseline models\", \"Performance tracking\"],\n",
    "                    \"code_files\": [\"evaluator.py\", \"metrics.py\", \"baselines.py\"],  \n",
    "                    \"effort_days\": 5\n",
    "                },\n",
    "                {\n",
    "                    \"task\": \"Model Training and Validation\",\n",
    "                    \"description\": \"Train CLLMate model and validate performance\",\n",
    "                    \"deliverables\": [\"Trained model weights\", \"Validation results\", \"Performance analysis\"],\n",
    "                    \"code_files\": [\"training_script.py\", \"validation.py\"],\n",
    "                    \"effort_days\":"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
